{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPYkJxl5nnvkCpdkGes4tyn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZenChaoSi/Cuda-Classic-Project/blob/main/Reduction%E7%AE%97%E5%AD%90%E4%BC%98%E5%8C%96.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 环境部署"
      ],
      "metadata": {
        "id": "-lrz-Spxdb89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "启用GPU并检查环境"
      ],
      "metadata": {
        "id": "sA7Gph3udhEm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmU8RppgdTlk",
        "outputId": "09a89cbc-a1f7-4514-8296-cfec3b53f38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "bin\tcompute-sanitizer  extras  include  nvml  share  targets\n",
            "compat\tdoc\t\t   gds\t   lib64    nvvm  src\n"
          ]
        }
      ],
      "source": [
        "# 检查GPU和CUDA信息\n",
        "!nvidia-smi\n",
        "!nvcc --version\n",
        "!ls /usr/local/cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "安装必要的编译工具"
      ],
      "metadata": {
        "id": "Yz2Mn2dgd2UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 更新包列表并安装必要的编译工具\n",
        "!apt-get update\n",
        "!apt-get install -y build-essential"
      ],
      "metadata": {
        "id": "ZuM0Y3vxd3NN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08bfccb-fc60-4ce8-a469-a0c8e5eb72f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [80.4 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,002 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,241 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [43.0 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,791 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,272 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,310 kB]\n",
            "Hit:16 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,580 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,623 kB]\n",
            "Fetched 24.4 MB in 8s (2,909 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "运行验证"
      ],
      "metadata": {
        "id": "E1VJp7tYd-G_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    int n = 1024;\n",
        "    int size = n * sizeof(int);\n",
        "\n",
        "    // 分配主机内存\n",
        "    int *h_a = new int[n];\n",
        "    int *h_b = new int[n];\n",
        "    int *h_c = new int[n];\n",
        "\n",
        "    // 初始化数组\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = i;\n",
        "        h_b[i] = i * 2;\n",
        "    }\n",
        "\n",
        "    // 分配设备内存\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        "\n",
        "    // 拷贝数据到设备\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // 启动核函数\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (n + blockSize - 1) / blockSize;\n",
        "    vectorAdd<<<numBlocks, blockSize>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "    // 拷贝结果回主机\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // 验证结果\n",
        "    bool success = true;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        if (h_c[i] != h_a[i] + h_b[i]) {\n",
        "            success = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (success) {\n",
        "        std::cout << \"向量加法测试成功!\" << std::endl;\n",
        "    } else {\n",
        "        std::cout << \"向量加法测试失败!\" << std::endl;\n",
        "    }\n",
        "\n",
        "    // 释放内存\n",
        "    delete[] h_a;\n",
        "    delete[] h_b;\n",
        "    delete[] h_c;\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHJWGfYdeHV3",
        "outputId": "88d92a43-f0af-4a0d-de3b-20e8377d8ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 明确指定 GPU 架构\n",
        "!nvcc -arch=sm_75 -o main main.cu"
      ],
      "metadata": {
        "id": "qtjTUN-7ee53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 运行程序\n",
        "!./main"
      ],
      "metadata": {
        "id": "N6iQHF1dejI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77e8bfcf-36d7-476f-9f66-d99643f1c39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./main: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reduce"
      ],
      "metadata": {
        "id": "1es1nWxdF3D7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reduce_Baseline"
      ],
      "metadata": {
        "id": "R2ujEsN3F6Wp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "一个线程做 Reduce"
      ],
      "metadata": {
        "id": "j13fyttIGAJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduce_baseline.cu\n",
        "\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "\n",
        "__global__ void reduce_baseline(const int* input, int* output, size_t n) {\n",
        "  int sum = 0;\n",
        "  for (size_t i = 0; i < n; ++i) {\n",
        "    sum += input[i];\n",
        "  }\n",
        "  *output = sum;\n",
        "}\n",
        "\n",
        "bool CheckResult(int *out, int groudtruth, int n){\n",
        "    if (*out != groudtruth) {\n",
        "        return false;\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N = 25600000;\n",
        "    const int blockSize = 1;\n",
        "    int GridSize = 1;\n",
        "\n",
        "    cudaSetDevice(0);\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, 0);\n",
        "\n",
        "    int *a = (int *)malloc(N * sizeof(int));\n",
        "    int *out = (int*)malloc((GridSize) * sizeof(int));\n",
        "    int *d_a, *d_out;\n",
        "    cudaMalloc((void **)&d_a, N * sizeof(int));\n",
        "    cudaMalloc((void **)&d_out, (GridSize) * sizeof(int));\n",
        "\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1;\n",
        "    }\n",
        "    int groudtruth = N * 1;\n",
        "\n",
        "    cudaMemcpy(d_a, a, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 Grid(GridSize);\n",
        "    dim3 Block(blockSize);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    reduce_baseline<<<Grid, Block>>>(d_a, d_out, N);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(out, d_out, GridSize * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    printf(\"allcated %d blocks, data counts are %d \\n\", GridSize, N);\n",
        "\n",
        "    bool is_right = CheckResult(out, groudtruth, GridSize);\n",
        "    if(is_right) {\n",
        "        printf(\"the ans is right\\n\");\n",
        "    } else {\n",
        "        printf(\"the ans is wrong\\n\");\n",
        "        for(int i = 0; i < GridSize;i++){\n",
        "            printf(\"res per block : %d \",out[i]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "        printf(\"groudtruth is: %d \\n\", groudtruth);\n",
        "    }\n",
        "\n",
        "    printf(\"reduce_baseline latency = %f ms\\n\", milliseconds);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_out);\n",
        "    free(a);\n",
        "    free(out);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C3refLrGC_9",
        "outputId": "9d50e9b7-32c8-4867-a9cb-4d8fbaac85ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting reduce_baseline.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_80 -o reduce_baseline reduce_baseline.cu"
      ],
      "metadata": {
        "id": "GcUpWbMEJiU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduce_baseline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbXzt2R-JpP4",
        "outputId": "9cb5655e-08ee-46d4-8309-73093d77a4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allcated 1 blocks, data counts are 25600000 \n",
            "the ans is right\n",
            "reduce_baseline latency = 1140.125854 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reduce_V0"
      ],
      "metadata": {
        "id": "X5yt7vj8jV0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "引入 Shared Memory 且并行化reduce算法"
      ],
      "metadata": {
        "id": "h4pTOjG3jZ0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduce_v0.cu\n",
        "\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "\n",
        "template<int blockSize>\n",
        "__global__ void reduce_v0(float *d_in,float *d_out){\n",
        "    __shared__ float smem[blockSize];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int gtid = blockIdx.x * blockSize + threadIdx.x;\n",
        "\n",
        "    smem[tid] = d_in[gtid];\n",
        "    __syncthreads();\n",
        "\n",
        "    for(int index = 1; index < blockDim.x; index *= 2) {\n",
        "        if (tid % (2 * index) == 0) {\n",
        "            smem[tid] += smem[tid + index];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) {\n",
        "        d_out[blockIdx.x] = smem[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "bool CheckResult(float *out, float groudtruth, int n){\n",
        "    float res = 0;\n",
        "    for (int i = 0; i < n; i++){\n",
        "        res += out[i];\n",
        "    }\n",
        "    if (res != groudtruth) {\n",
        "        return false;\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 25600000;\n",
        "    const int blockSize = 256;\n",
        "\n",
        "    cudaSetDevice(0);\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, 0);\n",
        "\n",
        "    int GridSize = std::min((N + 256 - 1) / 256, deviceProp.maxGridSize[0]);\n",
        "\n",
        "    float *a = (float *)malloc(N * sizeof(float));\n",
        "    float *d_a;\n",
        "    cudaMalloc((void **)&d_a, N * sizeof(float));\n",
        "    float *out = (float*)malloc((GridSize) * sizeof(float));\n",
        "    float *d_out;\n",
        "    cudaMalloc((void **)&d_out, (GridSize) * sizeof(float));\n",
        "\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f;\n",
        "    }\n",
        "    float groudtruth = N * 1.0f;\n",
        "\n",
        "    cudaMemcpy(d_a, a, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 Grid(GridSize);\n",
        "    dim3 Block(blockSize);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "    reduce_v0<blockSize><<<Grid,Block>>>(d_a, d_out);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(out, d_out, GridSize * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    printf(\"allcated %d blocks, data counts are %d \\n\", GridSize, N);\n",
        "\n",
        "    bool is_right = CheckResult(out, groudtruth, GridSize);\n",
        "    if(is_right) {\n",
        "        printf(\"the ans is right\\n\");\n",
        "    } else {\n",
        "        printf(\"the ans is wrong\\n\");\n",
        "        //for(int i = 0; i < GridSize;i++){\n",
        "            //printf(\"res per block : %lf \",out[i]);\n",
        "        //}\n",
        "        //printf(\"\\n\");\n",
        "        printf(\"groudtruth is: %f \\n\", groudtruth);\n",
        "    }\n",
        "\n",
        "    printf(\"reduce_v0 latency = %f ms\\n\", milliseconds);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_out);\n",
        "    free(a);\n",
        "    free(out);\n",
        "}"
      ],
      "metadata": {
        "id": "XlNe9EUNPbxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52fe5df-6fff-4a5c-9c09-5541de102362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting reduce_v0.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_80 -o reduce_v0 reduce_v0.cu"
      ],
      "metadata": {
        "id": "9FivxYTZomYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduce_v0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGiooud0ooy_",
        "outputId": "a6899628-aaeb-46b7-e01c-2ee676cf7ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allcated 100000 blocks, data counts are 25600000 \n",
            "the ans is right\n",
            "reduce_v0 latency = 0.767104 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reduce_V1"
      ],
      "metadata": {
        "id": "Axgy2nAnDiFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "用位运算来替代除余操作和除法操作"
      ],
      "metadata": {
        "id": "Gbq_Sb56EkaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduce_v1.cu\n",
        "\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "\n",
        "template<int blockSize>\n",
        "__global__ void reduce_v0(float *d_in,float *d_out){\n",
        "    __shared__ float smem[blockSize];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int gtid = blockIdx.x * blockSize + threadIdx.x;\n",
        "\n",
        "    smem[tid] = d_in[gtid];\n",
        "    __syncthreads();\n",
        "\n",
        "    for(int index = 1; index < blockDim.x; index *= 2) {\n",
        "        if ((tid & (2 * index - 1)) == 0) {\n",
        "            smem[tid] += smem[tid + index];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) {\n",
        "        d_out[blockIdx.x] = smem[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "bool CheckResult(float *out, float groudtruth, int n){\n",
        "    float res = 0;\n",
        "    for (int i = 0; i < n; i++){\n",
        "        res += out[i];\n",
        "    }\n",
        "    if (res != groudtruth) {\n",
        "        return false;\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N = 25600000;\n",
        "    const int blockSize = 256;\n",
        "\n",
        "    cudaSetDevice(0);\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, 0);\n",
        "\n",
        "    int GridSize = std::min((N + 256 - 1) / 256, deviceProp.maxGridSize[0]);\n",
        "\n",
        "    float *a = (float *)malloc(N * sizeof(float));\n",
        "    float *d_a;\n",
        "    cudaMalloc((void **)&d_a, N * sizeof(float));\n",
        "    float *out = (float*)malloc((GridSize) * sizeof(float));\n",
        "    float *d_out;\n",
        "    cudaMalloc((void **)&d_out, (GridSize) * sizeof(float));\n",
        "\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f;\n",
        "    }\n",
        "    float groudtruth = N * 1.0f;\n",
        "\n",
        "    cudaMemcpy(d_a, a, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 Grid(GridSize);\n",
        "    dim3 Block(blockSize);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "    reduce_v0<blockSize><<<Grid,Block>>>(d_a, d_out);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(out, d_out, GridSize * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    printf(\"allcated %d blocks, data counts are %d \\n\", GridSize, N);\n",
        "\n",
        "    bool is_right = CheckResult(out, groudtruth, GridSize);\n",
        "    if(is_right) {\n",
        "        printf(\"the ans is right\\n\");\n",
        "    } else {\n",
        "        printf(\"the ans is wrong\\n\");\n",
        "        //for(int i = 0; i < GridSize;i++){\n",
        "            //printf(\"res per block : %lf \",out[i]);\n",
        "        //}\n",
        "        //printf(\"\\n\");\n",
        "        printf(\"groudtruth is: %f \\n\", groudtruth);\n",
        "    }\n",
        "\n",
        "    printf(\"reduce_v0 latency = %f ms\\n\", milliseconds);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_out);\n",
        "    free(a);\n",
        "    free(out);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brG3GbAPDlnp",
        "outputId": "1445704e-6970-479c-99c6-3d1fa879e5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing reduce_v1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_80 -o reduce_v1 reduce_v1.cu"
      ],
      "metadata": {
        "id": "7U2b3NBxEnLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduce_v1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exPR8J5yEp6L",
        "outputId": "e2f5c2fd-f100-44c7-bf7a-f23a949e86c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allcated 100000 blocks, data counts are 25600000 \n",
            "the ans is right\n",
            "reduce_v0 latency = 0.399520 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reduce_V2"
      ],
      "metadata": {
        "id": "ATVHSpHtGNsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "消除 Shared Memory Bank Conflict"
      ],
      "metadata": {
        "id": "5S7jKdLFZ9hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduce_v2.cu\n",
        "\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "\n",
        "template<int blockSize>\n",
        "__global__ void reduce_v0(float *d_in,float *d_out){\n",
        "    __shared__ float smem[blockSize];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int gtid = blockIdx.x * blockSize + threadIdx.x;\n",
        "\n",
        "    smem[tid] = d_in[gtid];\n",
        "    __syncthreads();\n",
        "\n",
        "    for (unsigned int index = blockDim.x / 2; index > 0; index >>= 1) {\n",
        "        if (tid < index) {\n",
        "            smem[tid] += smem[tid + index];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) {\n",
        "        d_out[blockIdx.x] = smem[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "bool CheckResult(float *out, float groudtruth, int n){\n",
        "    float res = 0;\n",
        "    for (int i = 0; i < n; i++){\n",
        "        res += out[i];\n",
        "    }\n",
        "    if (res != groudtruth) {\n",
        "        return false;\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N = 25600000;\n",
        "    const int blockSize = 256;\n",
        "\n",
        "    cudaSetDevice(0);\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, 0);\n",
        "\n",
        "    int GridSize = std::min((N + 256 - 1) / 256, deviceProp.maxGridSize[0]);\n",
        "\n",
        "    float *a = (float *)malloc(N * sizeof(float));\n",
        "    float *d_a;\n",
        "    cudaMalloc((void **)&d_a, N * sizeof(float));\n",
        "    float *out = (float*)malloc((GridSize) * sizeof(float));\n",
        "    float *d_out;\n",
        "    cudaMalloc((void **)&d_out, (GridSize) * sizeof(float));\n",
        "\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f;\n",
        "    }\n",
        "    float groudtruth = N * 1.0f;\n",
        "\n",
        "    cudaMemcpy(d_a, a, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 Grid(GridSize);\n",
        "    dim3 Block(blockSize);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "    reduce_v0<blockSize><<<Grid,Block>>>(d_a, d_out);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(out, d_out, GridSize * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    printf(\"allcated %d blocks, data counts are %d \\n\", GridSize, N);\n",
        "\n",
        "    bool is_right = CheckResult(out, groudtruth, GridSize);\n",
        "    if(is_right) {\n",
        "        printf(\"the ans is right\\n\");\n",
        "    } else {\n",
        "        printf(\"the ans is wrong\\n\");\n",
        "        //for(int i = 0; i < GridSize;i++){\n",
        "            //printf(\"res per block : %lf \",out[i]);\n",
        "        //}\n",
        "        //printf(\"\\n\");\n",
        "        printf(\"groudtruth is: %f \\n\", groudtruth);\n",
        "    }\n",
        "\n",
        "    printf(\"reduce_v0 latency = %f ms\\n\", milliseconds);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_out);\n",
        "    free(a);\n",
        "    free(out);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj45ri4QbFHY",
        "outputId": "ed9efafc-b058-4005-a562-2c1a1d103168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing reduce_v2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_80 -o reduce_v2 reduce_v2.cu"
      ],
      "metadata": {
        "id": "XgqGhYlDbJ3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduce_v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaRXTK55bM4g",
        "outputId": "a438f3ca-1933-40a5-bd95-a63e319fad5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allcated 100000 blocks, data counts are 25600000 \n",
            "the ans is right\n",
            "reduce_v0 latency = 0.399232 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reduce_V3"
      ],
      "metadata": {
        "id": "f5m-VFexwl2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "最大化线程利用率（更多线程同时工作）"
      ],
      "metadata": {
        "id": "e-2npEpHwrZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduce_v3.cu\n",
        "\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "\n",
        "template<int blockSize>\n",
        "__global__ void reduce_v0(float *d_in,float *d_out){\n",
        "    __shared__ float smem[blockSize];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int gtid = blockIdx.x * blockSize * 2 + threadIdx.x;\n",
        "\n",
        "    smem[tid] = d_in[gtid] + d_in[gtid + blockSize];\n",
        "    __syncthreads();\n",
        "\n",
        "    for (unsigned int index = blockDim.x / 2; index > 0; index >>= 1) {\n",
        "        if (tid < index) {\n",
        "            smem[tid] += smem[tid + index];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) {\n",
        "        d_out[blockIdx.x] = smem[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "bool CheckResult(float *out, float groudtruth, int n){\n",
        "    float res = 0;\n",
        "    for (int i = 0; i < n; i++){\n",
        "        res += out[i];\n",
        "    }\n",
        "    if (res != groudtruth) {\n",
        "        return false;\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N = 25600000;\n",
        "    const int blockSize = 256;\n",
        "\n",
        "    cudaSetDevice(0);\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, 0);\n",
        "\n",
        "    int GridSize = std::min((N + 256 - 1) / 256, deviceProp.maxGridSize[0]);\n",
        "\n",
        "    float *a = (float *)malloc(N * sizeof(float));\n",
        "    float *d_a;\n",
        "    cudaMalloc((void **)&d_a, N * sizeof(float));\n",
        "    float *out = (float*)malloc((GridSize) * sizeof(float));\n",
        "    float *d_out;\n",
        "    cudaMalloc((void **)&d_out, (GridSize) * sizeof(float));\n",
        "\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f;\n",
        "    }\n",
        "    float groudtruth = N * 1.0f;\n",
        "\n",
        "    cudaMemcpy(d_a, a, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 Grid(GridSize);\n",
        "    dim3 Block(blockSize / 2);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "    reduce_v0<blockSize / 2><<<Grid,Block>>>(d_a, d_out);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(out, d_out, GridSize * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    printf(\"allcated %d blocks, data counts are %d \\n\", GridSize, N);\n",
        "\n",
        "    bool is_right = CheckResult(out, groudtruth, GridSize);\n",
        "    if(is_right) {\n",
        "        printf(\"the ans is right\\n\");\n",
        "    } else {\n",
        "        printf(\"the ans is wrong\\n\");\n",
        "        //for(int i = 0; i < GridSize;i++){\n",
        "            //printf(\"res per block : %lf \",out[i]);\n",
        "        //}\n",
        "        //printf(\"\\n\");\n",
        "        printf(\"groudtruth is: %f \\n\", groudtruth);\n",
        "    }\n",
        "\n",
        "    printf(\"reduce_v0 latency = %f ms\\n\", milliseconds);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_out);\n",
        "    free(a);\n",
        "    free(out);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn9IkR5QwsAW",
        "outputId": "5155f3b2-1f3f-4bcb-e27c-679b7053d5fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing reduce_v3.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_80 -o reduce_v3 reduce_v3.cu"
      ],
      "metadata": {
        "id": "kg89VeAYyKpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduce_v3"
      ],
      "metadata": {
        "id": "PpzXuvFMyM07",
        "outputId": "876c3812-ed58-4d00-cb3a-c2aa12113bcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allcated 100000 blocks, data counts are 25600000 \n",
            "the ans is right\n",
            "reduce_v0 latency = 0.286848 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reduce_V4"
      ],
      "metadata": {
        "id": "q8m2taqK5e6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "展开 for 循环最后一个 Warp"
      ],
      "metadata": {
        "id": "5Tix8gh15kLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduce_v4.cu\n",
        "\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "\n",
        "__device__ void WarpSharedMemReduce(volatile float* smem, int tid){\n",
        "    float x = smem[tid];\n",
        "    if (blockDim.x >= 64) {\n",
        "      x += smem[tid + 32]; __syncwarp();\n",
        "      smem[tid] = x; __syncwarp();\n",
        "    }\n",
        "    x += smem[tid + 16]; __syncwarp();\n",
        "    smem[tid] = x; __syncwarp();\n",
        "    x += smem[tid + 8]; __syncwarp();\n",
        "    smem[tid] = x; __syncwarp();\n",
        "    x += smem[tid + 4]; __syncwarp();\n",
        "    smem[tid] = x; __syncwarp();\n",
        "    x += smem[tid + 2]; __syncwarp();\n",
        "    smem[tid] = x; __syncwarp();\n",
        "    x += smem[tid + 1]; __syncwarp();\n",
        "    smem[tid] = x; __syncwarp();\n",
        "}\n",
        "\n",
        "template<int blockSize>\n",
        "__global__ void reduce_v4(float *d_in,float *d_out) {\n",
        "    __shared__ float smem[blockSize];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int i = blockIdx.x * (blockSize * 2) + threadIdx.x;\n",
        "    smem[tid] = d_in[i] + d_in[i + blockSize];\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int s = blockDim.x / 2; s > 32; s >>= 1) {\n",
        "        if (tid < s) {\n",
        "            smem[tid] += smem[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid < 32) {\n",
        "        WarpSharedMemReduce(smem, tid);\n",
        "    }\n",
        "\n",
        "    if (tid == 0) {\n",
        "        d_out[blockIdx.x] = smem[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "bool CheckResult(float *out, float groudtruth, int n){\n",
        "    float res = 0;\n",
        "    for (int i = 0; i < n; i++){\n",
        "        res += out[i];\n",
        "    }\n",
        "    if (res != groudtruth) {\n",
        "        return false;\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N = 25600000;\n",
        "    const int blockSize = 256;\n",
        "\n",
        "    cudaSetDevice(0);\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, 0);\n",
        "\n",
        "    int GridSize = std::min((N + 256 - 1) / 256, deviceProp.maxGridSize[0]);\n",
        "\n",
        "    float *a = (float *)malloc(N * sizeof(float));\n",
        "    float *d_a;\n",
        "    cudaMalloc((void **)&d_a, N * sizeof(float));\n",
        "    float *out = (float*)malloc((GridSize) * sizeof(float));\n",
        "    float *d_out;\n",
        "    cudaMalloc((void **)&d_out, (GridSize) * sizeof(float));\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        a[i] = 1.0f;\n",
        "    }\n",
        "    float groudtruth = N * 1.0f;\n",
        "\n",
        "    cudaMemcpy(d_a, a, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 Grid(GridSize);\n",
        "    dim3 Block(blockSize / 2);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    reduce_v4<blockSize / 2><<<Grid, Block>>>(d_a, d_out);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(out, d_out, GridSize * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    printf(\"allcated %d blocks, data counts are %d \\n\", GridSize, N);\n",
        "\n",
        "    bool is_right = CheckResult(out, groudtruth, GridSize);\n",
        "    if(is_right) {\n",
        "        printf(\"the ans is right\\n\");\n",
        "    } else {\n",
        "        printf(\"the ans is wrong\\n\");\n",
        "        printf(\"groudtruth is: %f \\n\", groudtruth);\n",
        "    }\n",
        "\n",
        "    printf(\"reduce_v4 latency = %f ms\\n\", milliseconds);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_out);\n",
        "    free(a);\n",
        "    free(out);\n",
        "}"
      ],
      "metadata": {
        "id": "_iS01abi5lcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a208a475-d944-4a24-b4f9-515cc234573b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing reduce_v4.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_80 -o reduce_v4 reduce_v4.cu"
      ],
      "metadata": {
        "id": "p5XqqXwO81HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduce_v4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlEKfApd84ZR",
        "outputId": "66e54e26-6e9b-427e-b0d9-b4c3805349ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allcated 100000 blocks, data counts are 25600000 \n",
            "the ans is right\n",
            "reduce_v4 latency = 0.271200 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reduce_V5"
      ],
      "metadata": {
        "id": "UyEnVdgqmxqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "完全展开 for 循环"
      ],
      "metadata": {
        "id": "CWpyqaxkm6Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduce_v5.cu\n",
        "\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "\n",
        "template <int blockSize>\n",
        "__device__ void BlockSharedMemReduce(float* smem) {\n",
        "  if (blockSize >= 1024) {\n",
        "    if (threadIdx.x < 512) {\n",
        "      smem[threadIdx.x] += smem[threadIdx.x + 512];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (blockSize >= 512) {\n",
        "    if (threadIdx.x < 256) {\n",
        "      smem[threadIdx.x] += smem[threadIdx.x + 256];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (blockSize >= 256) {\n",
        "    if (threadIdx.x < 128) {\n",
        "      smem[threadIdx.x] += smem[threadIdx.x + 128];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (blockSize >= 128) {\n",
        "    if (threadIdx.x < 64) {\n",
        "      smem[threadIdx.x] += smem[threadIdx.x + 64];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (threadIdx.x < 32) {\n",
        "    volatile float* vshm = smem;\n",
        "    if (blockDim.x >= 64) {\n",
        "      vshm[threadIdx.x] += vshm[threadIdx.x + 32];\n",
        "    }\n",
        "    vshm[threadIdx.x] += vshm[threadIdx.x + 16];\n",
        "    vshm[threadIdx.x] += vshm[threadIdx.x + 8];\n",
        "    vshm[threadIdx.x] += vshm[threadIdx.x + 4];\n",
        "    vshm[threadIdx.x] += vshm[threadIdx.x + 2];\n",
        "    vshm[threadIdx.x] += vshm[threadIdx.x + 1];\n",
        "  }\n",
        "}\n",
        "\n",
        "template <int blockSize>\n",
        "__global__ void reduce_v5(float *d_in, float *d_out){\n",
        "    __shared__ float smem[blockSize];\n",
        "\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x * (blockDim.x * 2) + threadIdx.x;\n",
        "\n",
        "    smem[tid] = d_in[i] + d_in[i + blockDim.x];\n",
        "    __syncthreads();\n",
        "\n",
        "    BlockSharedMemReduce<blockSize>(smem);\n",
        "\n",
        "    if (tid == 0) {\n",
        "        d_out[blockIdx.x] = smem[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "bool CheckResult(float *out, float groudtruth, int n){\n",
        "    float res = 0;\n",
        "    for (int i = 0; i < n; i++){\n",
        "        res += out[i];\n",
        "    }\n",
        "    if (res != groudtruth) {\n",
        "        return false;\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N = 25600000;\n",
        "    const int blockSize = 256;\n",
        "\n",
        "    cudaSetDevice(0);\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, 0);\n",
        "\n",
        "    int GridSize = std::min((N + 256 - 1) / 256, deviceProp.maxGridSize[0]);\n",
        "\n",
        "    float *a = (float *)malloc(N * sizeof(float));\n",
        "    float *d_a;\n",
        "    cudaMalloc((void **)&d_a, N * sizeof(float));\n",
        "    float *out = (float*)malloc((GridSize) * sizeof(float));\n",
        "    float *d_out;\n",
        "    cudaMalloc((void **)&d_out, (GridSize) * sizeof(float));\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        a[i] = 1.0f;\n",
        "    }\n",
        "    float groudtruth = N * 1.0f;\n",
        "\n",
        "    cudaMemcpy(d_a, a, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 Grid(GridSize);\n",
        "    dim3 Block(blockSize / 2);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    reduce_v5<blockSize / 2><<<Grid, Block>>>(d_a, d_out);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(out, d_out, GridSize * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    printf(\"allcated %d blocks, data counts are %d \\n\", GridSize, N);\n",
        "\n",
        "    bool is_right = CheckResult(out, groudtruth, GridSize);\n",
        "    if(is_right) {\n",
        "        printf(\"the ans is right\\n\");\n",
        "    } else {\n",
        "        printf(\"the ans is wrong\\n\");\n",
        "        printf(\"groudtruth is: %f \\n\", groudtruth);\n",
        "    }\n",
        "\n",
        "    printf(\"reduce_v5 latency = %f ms\\n\", milliseconds);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_out);\n",
        "    free(a);\n",
        "    free(out);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEmTjP7lnATJ",
        "outputId": "e53f12cf-f9ae-4c2d-d407-88fb9819c172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing reduce_v5.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_80 -o reduce_v5 reduce_v5.cu"
      ],
      "metadata": {
        "id": "YaUxTHmariG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduce_v5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdtRA_8onfYa",
        "outputId": "89241f2c-b67a-41ed-8812-37b8a835d794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allcated 100000 blocks, data counts are 25600000 \n",
            "the ans is right\n",
            "reduce_v5 latency = 0.272960 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reduce_V6"
      ],
      "metadata": {
        "id": "KmMv2q2wAeje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "单线程处理多个数据（增加计算强度）"
      ],
      "metadata": {
        "id": "XjiQ492PFtmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduce_v6.cu\n",
        "\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "\n",
        "template <int blockSize>\n",
        "__device__ void BlockSharedMemReduce(float* smem) {\n",
        "  if (blockSize >= 1024) {\n",
        "    if (threadIdx.x < 512) {\n",
        "      smem[threadIdx.x] += smem[threadIdx.x + 512];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (blockSize >= 512) {\n",
        "    if (threadIdx.x < 256) {\n",
        "      smem[threadIdx.x] += smem[threadIdx.x + 256];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (blockSize >= 256) {\n",
        "    if (threadIdx.x < 128) {\n",
        "      smem[threadIdx.x] += smem[threadIdx.x + 128];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (blockSize >= 128) {\n",
        "    if (threadIdx.x < 64) {\n",
        "      smem[threadIdx.x] += smem[threadIdx.x + 64];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (threadIdx.x < 32) {\n",
        "    volatile float* vshm = smem;\n",
        "    if (blockDim.x >= 64) {\n",
        "      vshm[threadIdx.x] += vshm[threadIdx.x + 32];\n",
        "    }\n",
        "    vshm[threadIdx.x] += vshm[threadIdx.x + 16];\n",
        "    vshm[threadIdx.x] += vshm[threadIdx.x + 8];\n",
        "    vshm[threadIdx.x] += vshm[threadIdx.x + 4];\n",
        "    vshm[threadIdx.x] += vshm[threadIdx.x + 2];\n",
        "    vshm[threadIdx.x] += vshm[threadIdx.x + 1];\n",
        "  }\n",
        "}\n",
        "\n",
        "template <int blockSize>\n",
        "__global__ void reduce_v6(float *d_in, float *d_out, int nums){\n",
        "    __shared__ float smem[blockSize];\n",
        "\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int gitd = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    unsigned int total_thread_num = blockDim.x * gridDim.x;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "    for (int32_t i = gitd; i < nums; i += total_thread_num) {\n",
        "        sum += d_in[i];\n",
        "    }\n",
        "    smem[tid] = sum;\n",
        "    __syncthreads();\n",
        "\n",
        "    BlockSharedMemReduce<blockSize>(smem);\n",
        "\n",
        "    if (tid == 0) {\n",
        "        d_out[blockIdx.x] = smem[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "bool CheckResult(float *out, float groudtruth, int n){\n",
        "    float res = 0;\n",
        "    for (int i = 0; i < n; i++){\n",
        "        res += out[i];\n",
        "    }\n",
        "    if (res != groudtruth) {\n",
        "        return false;\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 25600000;\n",
        "    const int blockSize = 256;\n",
        "\n",
        "    cudaSetDevice(0);\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, 0);\n",
        "\n",
        "    int GridSize = std::min((N + blockSize - 1) / 3 / blockSize, deviceProp.maxGridSize[0]);\n",
        "\n",
        "    float *a = (float *)malloc(N * sizeof(float));\n",
        "    float *d_a;\n",
        "    cudaMalloc((void **)&d_a, N * sizeof(float));\n",
        "    float *out = (float*)malloc((GridSize) * sizeof(float));\n",
        "    float *d_out;\n",
        "    cudaMalloc((void **)&d_out, (GridSize) * sizeof(float));\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        a[i] = 1.0f;\n",
        "    }\n",
        "    float groudtruth = N * 1.0f;\n",
        "\n",
        "    cudaMemcpy(d_a, a, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 Grid(GridSize);\n",
        "    dim3 Block(blockSize);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    reduce_v6<blockSize><<<Grid, Block>>>(d_a, d_out, N);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(out, d_out, GridSize * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    printf(\"allcated %d blocks, data counts are %d \\n\", GridSize, N);\n",
        "\n",
        "    bool is_right = CheckResult(out, groudtruth, GridSize);\n",
        "    if (is_right) {\n",
        "        printf(\"the ans is right\\n\");\n",
        "    } else {\n",
        "        printf(\"the ans is wrong\\n\");\n",
        "        printf(\"groudtruth is: %f \\n\", groudtruth);\n",
        "    }\n",
        "\n",
        "    printf(\"reduce_v6 latency = %f ms\\n\", milliseconds);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_out);\n",
        "    free(a);\n",
        "    free(out);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvWsCpKpF1mB",
        "outputId": "4f9acb09-866d-4236-eeb9-de54871178e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing reduce_v6.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_80 -o reduce_v6 reduce_v6.cu"
      ],
      "metadata": {
        "id": "IwJ0vzV4Go-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduce_v6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNIdfC_vGxDl",
        "outputId": "87a737c3-c7d8-4af4-aa84-838917295514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allcated 33333 blocks, data counts are 25600000 \n",
            "the ans is right\n",
            "reduce_v6 latency = 0.261632 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reduce_V7"
      ],
      "metadata": {
        "id": "aAdmldlzFQ9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用 ​​Warp Shuffle​​ 替代 Shared Memory"
      ],
      "metadata": {
        "id": "c0Z2jAqPFYaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduce_v7.cu\n",
        "\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "\n",
        "#define WarpSize 32\n",
        "\n",
        "//template <int blockSize>\n",
        "__device__ float WarpShuffle(float sum) {\n",
        "    sum += __shfl_down_sync(0xffffffff, sum, 16); // 0-16, 1-17, 2-18, etc.\n",
        "    sum += __shfl_down_sync(0xffffffff, sum, 8);// 0-8, 1-9, 2-10, etc.\n",
        "    sum += __shfl_down_sync(0xffffffff, sum, 4);// 0-4, 1-5, 2-6, etc.\n",
        "    sum += __shfl_down_sync(0xffffffff, sum, 2);// 0-2, 1-3, 4-6, 5-7, etc.\n",
        "    sum += __shfl_down_sync(0xffffffff, sum, 1);// 0-1, 2-3, 4-5, etc.\n",
        "    return sum;\n",
        "}\n",
        "\n",
        "template <int blockSize>\n",
        "__global__ void reduce_warp_level(float *d_in, float *d_out, unsigned int n) {\n",
        "    constexpr unsigned int WarpShift = 5;  // 2^5 = 32\n",
        "\n",
        "    float sum = 0;\n",
        "\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int gtid = blockIdx.x * blockSize + tid;\n",
        "    unsigned int total_thread_num = blockSize * gridDim.x;\n",
        "\n",
        "    // 循环展开的并行归约\n",
        "    for (unsigned int i = gtid; i < n; i += total_thread_num) {\n",
        "        sum += d_in[i];\n",
        "    }\n",
        "\n",
        "    __shared__ float WarpSums[blockSize >> WarpShift];  // blockSize / WarpSize\n",
        "\n",
        "    // 使用位运算替代取模和除法\n",
        "    const unsigned int laneId = tid & (WarpSize - 1);   // tid % WarpSize\n",
        "    const unsigned int warpId = tid >> WarpShift;       // tid / WarpSize\n",
        "\n",
        "    // Warp级别的归约 (使用洗牌指令)\n",
        "    sum = WarpShuffle(sum);\n",
        "\n",
        "    // 每个warp的第一个线程存储结果\n",
        "    if (laneId == 0) {\n",
        "        WarpSums[warpId] = sum;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // 仅前 warpId 线程参与最终归约\n",
        "    sum = (tid < (blockSize >> WarpShift)) ? WarpSums[tid] : 0;\n",
        "\n",
        "    // 最后一个warp的归约\n",
        "    if (warpId == 0) {\n",
        "        sum = WarpShuffle(sum);\n",
        "    }\n",
        "\n",
        "    // 块结果写入全局内存\n",
        "    if (tid == 0) {\n",
        "        d_out[blockIdx.x] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "bool CheckResult(float *out, float groudtruth, int n){\n",
        "    float res = 0;\n",
        "    for (int i = 0; i < n; i++){\n",
        "        res += out[i];\n",
        "    }\n",
        "    if (res != groudtruth) {\n",
        "        return false;\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    cudaSetDevice(0);\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, 0);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    const int N = 25600000;\n",
        "    const int blockSize = 256;\n",
        "    int GridSize = std::min((N + 256 - 1) / 256, deviceProp.maxGridSize[0]);\n",
        "\n",
        "    float *a = (float *)malloc(N * sizeof(float));\n",
        "    float *d_a;\n",
        "    cudaMalloc((void **)&d_a, N * sizeof(float));\n",
        "    float *out = (float*)malloc((GridSize) * sizeof(float));\n",
        "    float *d_out;\n",
        "    cudaMalloc((void **)&d_out, (GridSize) * sizeof(float));\n",
        "\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f;\n",
        "    }\n",
        "    float groudtruth = N * 1.0f;\n",
        "\n",
        "    cudaMemcpy(d_a, a, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 Grid(GridSize);\n",
        "    dim3 Block(blockSize);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "    reduce_warp_level<blockSize><<<Grid,Block>>>(d_a, d_out, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(out, d_out, GridSize * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    printf(\"allcated %d blocks, data counts are %d \\n\", GridSize, N);\n",
        "    bool is_right = CheckResult(out, groudtruth, GridSize);\n",
        "    if(is_right) {\n",
        "        printf(\"the ans is right\\n\");\n",
        "    } else {\n",
        "        printf(\"the ans is wrong\\n\");\n",
        "        for(int i = 0; i < GridSize;i++){\n",
        "            printf(\"resPerBlock : %lf \",out[i]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "        printf(\"groudtruth is: %f \\n\", groudtruth);\n",
        "    }\n",
        "    printf(\"reduce_warp_level latency = %f ms\\n\", milliseconds);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_out);\n",
        "    free(a);\n",
        "    free(out);\n",
        "}"
      ],
      "metadata": {
        "id": "-oJlHDitFY9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3c6798-c043-45d3-ef73-df3fde277fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting reduce_v7.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_80 -o reduce_v7 reduce_v7.cu"
      ],
      "metadata": {
        "id": "_O900DI9kdZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduce_v7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CzYPjBAkglo",
        "outputId": "c68421ff-79a5-4ab0-fc6a-a047a233df2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allcated 100000 blocks, data counts are 25600000 \n",
            "the ans is right\n",
            "reduce_warp_level latency = 0.285952 ms\n"
          ]
        }
      ]
    }
  ]
}